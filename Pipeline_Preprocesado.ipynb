{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbae42fe",
   "metadata": {},
   "source": [
    "# PREPROCESAMIENTO DE LOS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "689ac73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import keyword_only\n",
    "from pyspark.ml.param.shared import *\n",
    "from pyspark.ml.util import DefaultParamsReadable, DefaultParamsWritable\n",
    "from pyspark.ml.pipeline import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.ml.pipeline import Estimator, Model, Pipeline\n",
    "import pyspark.sql.functions as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d146c9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/06/23 00:58:45 WARN Utils: Your hostname, lu-Aspire-A515-55 resolves to a loopback address: 127.0.1.1, but we couldn't find any external IP address!\n",
      "22/06/23 00:58:45 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/06/23 00:58:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/06/23 00:58:46 WARN MacAddressUtil: Failed to find a usable hardware address from the network interfaces; using random bytes: 5f:15:32:12:fe:9a:ab:0a\n",
      "22/06/23 00:58:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Pipeline Preprocesado\").master(\"local\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a41b30",
   "metadata": {},
   "source": [
    "En este apartado vamos a realizar una serie de técnicas de preprocesamiento de datos que vamos a aplicar a nuestro conjunto de datos. Implementaremos cada paso de la Pipeline con la estructura de clases descrita de MLlib. Cada paso del preprocesamiento se desarrollará para que funcione de forma independiente y además después se incluirá en una Pipeline para poder aplicarlos también todos a la vez. Por último guardaremos dicha Pipeline para usarla cuando ajustemos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff4d988",
   "metadata": {},
   "source": [
    "1) Detección de variables constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a502728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clase que inicializa el parámetro único\n",
    "class HasColumnasConstantes(Params):\n",
    "    def __init__(self):\n",
    "        super(HasColumnasConstantes, self).__init__()\n",
    "        self.columnasConstantes = Param(self, \"columnasConstantes\", \"columnasConstantes\", \n",
    "                                        typeConverter=TypeConverters.identity)\n",
    "        \n",
    "    def setColumnasConstantes(self, value):\n",
    "        return self.set(self.columnasConstantes, value)\n",
    "\n",
    "    def getColumnasConstantes(self):\n",
    "        return self.getOrDefault(self.columnasConstantes)\n",
    "\n",
    "# Clase que define el estimador\n",
    "class DeteccionConstantesEstimator(Estimator, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    @keyword_only\n",
    "    def __init__(self):\n",
    "        super(DeteccionConstantesEstimator, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "    \n",
    "    @keyword_only\n",
    "    def setParams(self):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def eliminacion_constantes(df):\n",
    "        columnas = df.columns\n",
    "        columnas_constantes = []\n",
    "        s = len(df.columns)\n",
    "        for i, columna in zip(range(s), columnas):\n",
    "            valores_distintos = df.dropna(subset=[columna]).select(columna).distinct().count()\n",
    "            if valores_distintos<=1:\n",
    "                columnas_constantes.append(columna)\n",
    "        return columnas_constantes\n",
    "    \n",
    "    def _fit(self, df):\n",
    "        columnas_constantes = self. eliminacion_constantes(df)\n",
    "        return DeteccionConstantesModel(columnasConstantes=columnas_constantes)\n",
    "\n",
    "# Clase que define el transformer\n",
    "class DeteccionConstantesModel(Model, HasColumnasConstantes,  DefaultParamsReadable, DefaultParamsWritable):\n",
    "    @keyword_only\n",
    "    def __init__(self, columnasConstantes=[]):\n",
    "        super(DeteccionConstantesModel, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, columnasConstantes=[]):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def _transform(self, df):\n",
    "        columnas_constantes = self.getColumnasConstantes()\n",
    "        try:\n",
    "            df_final = df.drop(*columnas_constantes)\n",
    "        except:\n",
    "            df_final = list([])\n",
    "        return df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc22c2d",
   "metadata": {},
   "source": [
    "2) Imputación de Missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44964794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clases que inicializan los distintos parámetros del algoritmo\n",
    "class HasColumnasMissingsImputarCategoricas(Params):\n",
    "    def __init__(self):\n",
    "        super(HasColumnasMissingsImputarCategoricas, self).__init__()\n",
    "        self.columnasMissingsImputarCategoricas = Param(self, \"columnasMissingsImputarCategoricas\", \n",
    "                                                        \"columnasMissingsImputarCategoricas\", \n",
    "                                        typeConverter=TypeConverters.identity)\n",
    "        \n",
    "    def setColumnasMissingsImputarCategoricas(self, value):\n",
    "        return self.set(self.columnasMissingsImputarCategoricas, value)\n",
    "\n",
    "    def getColumnasMissingsImputarCategoricas(self):\n",
    "        return self.getOrDefault(self.columnasMissingsImputarCategoricas)\n",
    "\n",
    "class HasColumnasMissingsImputarNumericas(Params):\n",
    "    def __init__(self):\n",
    "        super(HasColumnasMissingsImputarNumericas, self).__init__()\n",
    "        self.columnasMissingsImputarNumericas = Param(self, \"columnasMissingsImputarNumericas\", \n",
    "                                                        \"columnasMissingsImputarNumericas\", \n",
    "                                        typeConverter=TypeConverters.identity)\n",
    "        \n",
    "    def setColumnasMissingsImputarNumericas(self, value):\n",
    "        return self.set(self.columnasMissingsImputarNumericas, value)\n",
    "\n",
    "    def getColumnasMissingsImputarNumericas(self):\n",
    "        return self.getOrDefault(self.columnasMissingsImputarNumericas)\n",
    "\n",
    "class HasColumnasMissingsEliminar(Params):\n",
    "    def __init__(self):\n",
    "        super(HasColumnasMissingsEliminar, self).__init__()\n",
    "        self.columnasMissingsEliminar = Param(self, \"columnasMissingsEliminar\", \"columnasMissingsEliminar\", \n",
    "                                        typeConverter=TypeConverters.identity)\n",
    "        \n",
    "    def setColumnasMissingsEliminar(self, value):\n",
    "        return self.set(self.columnasMissingsEliminar, value)\n",
    "\n",
    "    def getColumnasMissingsEliminar(self):\n",
    "        return self.getOrDefault(self.columnasMissingsEliminar)\n",
    "    \n",
    "class HasListaMissingsModas(Params):\n",
    "    def __init__(self):\n",
    "        super(HasListaMissingsModas, self).__init__()\n",
    "        self.listaMissingsModas = Param(self, \"listaMissingsModas\", \"listaMissingsModas\", \n",
    "                                        typeConverter=TypeConverters.identity)\n",
    "        \n",
    "    def setListaMissingsModas(self, value):\n",
    "        return self.set(self.listaMissingsModas, value)\n",
    "\n",
    "    def getListaMissingsModas(self):\n",
    "        return self.getOrDefault(self.listaMissingsModas)\n",
    "\n",
    "class HasListaMissingsMedianas(Params):\n",
    "    def __init__(self):\n",
    "        super(HasListaMissingsMedianas, self).__init__()\n",
    "        self.listaMissingsMedianas = Param(self, \"listaMissingsMedianas\", \"listaMissingsMedianas\", \n",
    "                                        typeConverter=TypeConverters.identity)\n",
    "        \n",
    "    def setListaMissingsMedianas(self, value):\n",
    "        return self.set(self.listaMissingsMedianas, value)\n",
    "\n",
    "    def getListaMissingsMedianas(self):\n",
    "        return self.getOrDefault(self.listaMissingsMedianas)\n",
    "\n",
    "class HasListaMissingsMedias(Params):\n",
    "    def __init__(self):\n",
    "        super(HasListaMissingsMedias, self).__init__()\n",
    "        self.listaMissingsMedias = Param(self, \"listaMissingsMedias\", \"listaMissingsMedias\", \n",
    "                                        typeConverter=TypeConverters.identity)\n",
    "        \n",
    "    def setListaMissingsMedias(self, value):\n",
    "        return self.set(self.listaMissingsMedias, value)\n",
    "\n",
    "    def getListaMissingsMedias(self):\n",
    "        return self.getOrDefault(self.listaMissingsMedias)\n",
    "    \n",
    "class HasPorcentajeMissings(Params):\n",
    "    def __init__(self):\n",
    "        super(HasPorcentajeMissings, self).__init__()\n",
    "        self.porcentajeMissings = Param(self, \"porcentajeMissings\", \"porcentajeMissings\", \n",
    "                                        typeConverter=TypeConverters.identity)\n",
    "        \n",
    "    def setPorcentajeMissings(self, value):\n",
    "        return self.set(self.porcentajeMissings, value)\n",
    "\n",
    "    def getPorcentajeMissings(self):\n",
    "        return self.getOrDefault(self.porcentajeMissings)\n",
    "\n",
    "class HasMetodoImputacionNumericas(Params):\n",
    "    def __init__(self):\n",
    "        super(HasMetodoImputacionNumericas, self).__init__()\n",
    "        self.metodoImputacionNumericas = Param(self, \"metodoImputacionNumericas\", \"metodoImputacionNumericas\", \n",
    "                                        typeConverter=TypeConverters.identity)\n",
    "        \n",
    "    def setMetodoImputacionNumericas(self, value):\n",
    "        return self.set(self.metodoImputacionNumericas, value)\n",
    "\n",
    "    def getMetodoImputacionNumericas(self):\n",
    "        return self.getOrDefault(self.metodoImputacionNumericas)    \n",
    "\n",
    "# Clase que define el estimador\n",
    "class ImputacionMissingsEstimator(Estimator, HasPorcentajeMissings, HasMetodoImputacionNumericas, \n",
    "                                  DefaultParamsReadable, DefaultParamsWritable):\n",
    "    \n",
    "    @keyword_only\n",
    "    def __init__(self, porcentajeMissings = 0.05, metodoImputacionNumericas = \"media\"):\n",
    "        super(ImputacionMissingsEstimator, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "    \n",
    "    @keyword_only\n",
    "    def setParams(self, porcentajeMissings = 0.05, metodoImputacionNumericas = \"media\"):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def deteccion_missings(self, df):\n",
    "        porcentaje_missings = self.getPorcentajeMissings()\n",
    "        columnas_missings_imputar_categoricas = []\n",
    "        columnas_missings_imputar_numericas = []\n",
    "        columnas_missings_eliminar = []\n",
    "        df_size = df.count()\n",
    "        if \"target\" in df.columns:\n",
    "            columnas_sin_target = df.drop(\"target\").columns\n",
    "        else:\n",
    "            columnas_sin_target = df.columns\n",
    "        for c in columnas_sin_target:\n",
    "            missing_porcentaje = df.select([(p.count(p.when(p.isnan(c) | p.col(c).isNull(), c))/df_size)\n",
    "                                            .alias(c)]).collect()[0][0]\n",
    "            if missing_porcentaje > porcentaje_missings:\n",
    "                columnas_missings_eliminar.append(c)\n",
    "            elif missing_porcentaje != 0:\n",
    "                if df.select(c).dtypes[0][1].startswith('string'):\n",
    "                    columnas_missings_imputar_categoricas.append(c)\n",
    "                elif df.select(c).dtypes[0][1] in [\"int\", \"float\", \"double\", \"long\", \"decimal\"]:\n",
    "                    columnas_missings_imputar_numericas.append(c)\n",
    "        return columnas_missings_imputar_categoricas, columnas_missings_imputar_numericas, columnas_missings_eliminar\n",
    "    \n",
    "    @staticmethod\n",
    "    def calcular_moda(df, columnas):\n",
    "        lista_modas = []\n",
    "        for columna in columnas:\n",
    "            contador = df.groupby(columna).count().sort(p.col(\"count\").desc())\n",
    "            contador = contador.na.drop()\n",
    "            moda = contador.first()[0]\n",
    "            lista_modas.append(moda)\n",
    "        return lista_modas\n",
    "    \n",
    "    @staticmethod\n",
    "    def calcular_mediana(df, columnas):\n",
    "        lista_medianas = df.approxQuantile(columnas, [0.5], 0.01)\n",
    "        lista_medianas = [x for xs in lista_medianas for x in xs]\n",
    "        return lista_medianas\n",
    "       \n",
    "    @staticmethod\n",
    "    def calcular_media(df, columnas):\n",
    "        lista_medias = list(df.select(p.avg(columna)).na.drop().collect()[0][0] for columna in columnas)\n",
    "        return lista_medias\n",
    "        \n",
    "    def _fit(self, df):\n",
    "        lista_modas=[]\n",
    "        lista_medias=[]\n",
    "        lista_medianas=[]\n",
    "        columnas_missings_imputar_categoricas, columnas_missings_imputar_numericas, columnas_missings_eliminar = self.deteccion_missings(df)\n",
    "        lista_modas = self.calcular_moda(df, columnas_missings_imputar_categoricas)\n",
    "        metodo = self.getMetodoImputacionNumericas()\n",
    "        if metodo == \"Media\":\n",
    "            lista_medias = self.calcular_media(df, columnas_missings_imputar_numericas)\n",
    "        if metodo == \"Mediana\":\n",
    "            lista_medianas = self.calcular_mediana(df, columnas_missings_imputar_numericas)\n",
    "        return ImputacionMissingsModel(columnasMissingsImputarCategoricas=columnas_missings_imputar_categoricas,\n",
    "                                       columnasMissingsImputarNumericas=columnas_missings_imputar_numericas, \n",
    "                                       columnasMissingsEliminar=columnas_missings_eliminar,\n",
    "                                       listaMissingsModas=lista_modas, listaMissingsMedianas=lista_medianas, \n",
    "                                       listaMissingsMedias=lista_medias, metodoImputacionNumericas=metodo)\n",
    "\n",
    "# Clase que define el transformer\n",
    "class ImputacionMissingsModel(Model, HasColumnasMissingsImputarCategoricas, HasColumnasMissingsImputarNumericas, \n",
    "                              HasColumnasMissingsEliminar, \n",
    "                              HasListaMissingsModas, HasMetodoImputacionNumericas, HasListaMissingsMedias,\n",
    "                              HasListaMissingsMedianas, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    @keyword_only\n",
    "    def __init__(self, columnasMissingsImputarCategoricas=[], columnasMissingsImputarNumericas=[],\n",
    "                 columnasMissingsEliminar=[], listaMissingsModas=\"\", listaMissingsMedianas=\"\", \n",
    "                 listaMissingsMedias=\"\", metodoImputacionNumericas=\"media\"):\n",
    "        super(ImputacionMissingsModel, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, columnasMissingsImputarCategoricas=[], columnasMissingsImputarNumericas=[], \n",
    "                  columnasMissingsEliminar=[], listaMissingsModas=\"\", listaMissingsMedianas=\"\", \n",
    "                  listaMissingsMedias=\"\", metodoImputacionNumericas=\"media\"):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def _transform(self, df):\n",
    "        columnas_missings_eliminar = self.getColumnasMissingsEliminar()\n",
    "        columnas_missings_imputar_categoricas = self.getColumnasMissingsImputarCategoricas()\n",
    "        columnas_missings_imputar_numericas = self.getColumnasMissingsImputarNumericas()\n",
    "        for i in columnas_missings_eliminar:\n",
    "            df = df.drop(i)\n",
    "        for i in columnas_missings_imputar_categoricas:\n",
    "            lista_modas = self.getListaMissingsModas()          \n",
    "            diccionario_imputacion = dict(zip(columnas_missings_imputar_categoricas, lista_modas))\n",
    "            df = df.fillna(diccionario_imputacion)\n",
    "        metodo = self.getMetodoImputacionNumericas()\n",
    "        for i in columnas_missings_imputar_numericas:\n",
    "            if metodo == \"Media\":\n",
    "                lista_medias = self.getListaMissingsMedias()\n",
    "                diccionario_imputacion = dict(zip(columnas_missings_imputar_numericas, lista_medias))\n",
    "                df = df.fillna(diccionario_imputacion)\n",
    "            if metodo == \"Mediana\":\n",
    "                lista_medianas = self.getListaMissingsMedianas()\n",
    "                diccionario_imputacion = dict(zip(columnas_missings_imputar_numericas, lista_medianas))\n",
    "                df = df.fillna(diccionario_imputacion)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0561aa",
   "metadata": {},
   "source": [
    "3) Detección e imputación de Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b857d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HasColumnasOutliers(Params):\n",
    "    def __init__(self):\n",
    "        super(HasColumnasOutliers, self).__init__()\n",
    "        self.columnasOutliers = Param(self, \"columnasOutliers\", \"columnasOutliers\", \n",
    "                                        typeConverter=TypeConverters.identity)\n",
    "        \n",
    "    def setColumnasOutliers(self, value):\n",
    "        return self.set(self.columnasOutliers, value)\n",
    "\n",
    "    def getColumnasOutliers(self):\n",
    "        return self.getOrDefault(self.columnasOutliers)\n",
    "    \n",
    "class HasMetodoOutliers(Params):\n",
    "    def __init__(self):\n",
    "        super(HasMetodoOutliers, self).__init__()\n",
    "        self.metodoOutliers = Param(self, \"metodoOutliers\", \"metodoOutliers\", \n",
    "                                        typeConverter=TypeConverters.identity)\n",
    "        \n",
    "    def setMetodoOutliers(self, value):\n",
    "        return self.set(self.metodoOutliers, value)\n",
    "\n",
    "    def getMetodoOutliers(self):\n",
    "        return self.getOrDefault(self.metodoOutliers)\n",
    "    \n",
    "class HasListaOutliersMedianas(Params):\n",
    "    def __init__(self):\n",
    "        super(HasListaOutliersMedianas, self).__init__()\n",
    "        self.listaOutliersMedianas = Param(self, \"listaOutliersMedianas\", \"listaOutliersMedianas\", \n",
    "                                        typeConverter=TypeConverters.identity)\n",
    "        \n",
    "    def setListaOutliersMedianas(self, value):\n",
    "        return self.set(self.listaOutliersMedianas, value)\n",
    "\n",
    "    def getListaOutliersMedianas(self):\n",
    "        return self.getOrDefault(self.listaOutliersMedianas)\n",
    "\n",
    "class HasListaOutliersMedias(Params):\n",
    "    def __init__(self):\n",
    "        super(HasListaOutliersMedias, self).__init__()\n",
    "        self.listaOutliersMedias = Param(self, \"listaOutliersMedias\", \"listaOutliersMedias\", \n",
    "                                        typeConverter=TypeConverters.identity)\n",
    "        \n",
    "    def setListaOutliersMedias(self, value):\n",
    "        return self.set(self.listaOutliersMedias, value)\n",
    "\n",
    "    def getListaOutliersMedias(self):\n",
    "        return self.getOrDefault(self.listaOutliersMedias)\n",
    "\n",
    "class HasBounds(Params):\n",
    "    def __init__(self):\n",
    "        super(HasBounds, self).__init__()\n",
    "        self.bounds = Param(self, \"bounds\", \"bounds\", \n",
    "                                        typeConverter=TypeConverters.identity)\n",
    "        \n",
    "    def setBounds(self, value):\n",
    "        return self.set(self.bounds, value)\n",
    "\n",
    "    def getBounds(self):\n",
    "        return self.getOrDefault(self.bounds)\n",
    "    \n",
    "# Clase que define el estimador\n",
    "class OutliersEstimator(Estimator, HasMetodoOutliers, \n",
    "                                  DefaultParamsReadable, DefaultParamsWritable):\n",
    "    \n",
    "    @keyword_only\n",
    "    def __init__(self, metodoOutliers = \"media\"):\n",
    "        super(OutliersEstimator, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "    \n",
    "    @keyword_only\n",
    "    def setParams(self, metodoOutliers = \"media\"):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "    \n",
    "    @staticmethod\n",
    "    def calcular_mediana(df, columnas):\n",
    "        lista_medianas = df.approxQuantile(columnas, [0.5], 0.01)\n",
    "        lista_medianas = [x for xs in lista_medianas for x in xs]\n",
    "        return lista_medianas\n",
    "       \n",
    "    @staticmethod\n",
    "    def calcular_media(df, columnas):\n",
    "        lista_medias = list(df.select(p.avg(columna)).na.drop().collect()[0][0] for columna in columnas)\n",
    "        return lista_medias\n",
    "    @staticmethod\n",
    "    def calcular_limites(df, columnas):\n",
    "        bounds = {\n",
    "            c: dict(\n",
    "                zip([\"q1\", \"q3\"], df.approxQuantile(c, [0.25, 0.75], 0.01))\n",
    "            )\n",
    "            for c in columnas\n",
    "        }\n",
    "        for c in bounds:\n",
    "            iqr = bounds[c]['q3'] - bounds[c]['q1']\n",
    "            bounds[c]['lower'] = bounds[c]['q1'] - (iqr * 1.5)\n",
    "            bounds[c]['upper'] = bounds[c]['q3'] + (iqr * 1.5)\n",
    "        return bounds\n",
    "    \n",
    "    def _fit(self, df):\n",
    "        lista_medias=[]\n",
    "        lista_medianas=[]\n",
    "        columnas_numericas=[]\n",
    "        if \"target\" in df.columns:\n",
    "            columnas_sin_target = df.drop(\"target\").columns\n",
    "        else:\n",
    "            columnas_sin_target = df.columns\n",
    "        for c in columnas_sin_target:\n",
    "            if df.select(c).dtypes[0][1] in [\"int\", \"float\", \"double\", \"long\", \"decimal\"]:\n",
    "                columnas_numericas.append(c)\n",
    "        metodo = self.getMetodoOutliers()\n",
    "        bounds = self.calcular_limites(df, columnas_numericas)\n",
    "        if metodo == \"Media\":\n",
    "            lista_medias = self.calcular_media(df, columnas_numericas)\n",
    "        if metodo == \"Mediana\":\n",
    "            lista_medianas = self.calcular_mediana(df, columnas_numericas)\n",
    "        return OutliersModel(columnasOutliers=columnas_numericas,\n",
    "                                       listaOutliersMedianas=lista_medianas, \n",
    "                                       listaOutliersMedias=lista_medias, metodoOutliers=metodo, bounds=bounds)\n",
    "\n",
    "# Clase que define el transformer\n",
    "class OutliersModel(Model, HasColumnasOutliers, HasListaOutliersMedianas, HasListaOutliersMedias, \n",
    "                    HasMetodoOutliers, HasBounds, DefaultParamsReadable, DefaultParamsWritable):\n",
    "    @keyword_only\n",
    "    def __init__(self, columnasOutliers = \"\", listaOutliersMedianas=\"\", listaOutliersMedias=\"\", \n",
    "                 metodoOutliers=\"media\", bounds=\"\"):\n",
    "        super(OutliersModel, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, columnasOutliers = \"\", listaOutliersMedianas=\"\", listaOutliersMedias=\"\", \n",
    "                  metodoOutliers=\"media\", bounds=\"\"):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "\n",
    "    def _transform(self, df):\n",
    "        columnas_numericas = self.getColumnasOutliers()\n",
    "        metodo = self.getMetodoOutliers()\n",
    "        bounds = self.getBounds()\n",
    "        if metodo == \"Media\":\n",
    "            lista_medias = self.getListaOutliersMedias()\n",
    "            for c in columnas_numericas:\n",
    "                df=df.withColumn(c, p.when(\n",
    "                            p.col(c).between(bounds[c]['lower'], bounds[c]['upper']),\n",
    "                            p.col(c)\n",
    "                        ).otherwise(lista_medias[int(columnas_numericas.index(c))]))\n",
    "        if metodo == \"Mediana\":\n",
    "            lista_medianas = self.getListaOutliersMedianas()\n",
    "            for c in columnas_numericas:\n",
    "                df=df.withColumn(c, p.when(\n",
    "                            p.col(c).between(bounds[c]['lower'], bounds[c]['upper']),\n",
    "                            p.col(c)\n",
    "                        ).otherwise(lista_medianas[int(columnas_numericas.index(c))]))\n",
    "   \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e9404f",
   "metadata": {},
   "source": [
    "4) Codificación de Variables Categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7865494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HasColumnasCod(Params):\n",
    "    def __init__(self):\n",
    "        super(HasColumnasCod, self).__init__()\n",
    "        self.columnasCod = Param(self, \"columnasCod\", \"columnasCod\", \n",
    "                                        typeConverter=TypeConverters.identity)\n",
    "        \n",
    "    def setColumnasCod(self, value):\n",
    "        return self.set(self.columnasCod, value)\n",
    "\n",
    "    def getColumnasCod(self):\n",
    "        return self.getOrDefault(self.columnasCod)\n",
    "    \n",
    "class HasMetodoCod(Params):\n",
    "    def __init__(self):\n",
    "        super(HasMetodoCod, self).__init__()\n",
    "        self.metodoCod = Param(self, \"metodoCod\", \"metodoCod\", \n",
    "                                        typeConverter=TypeConverters.identity)\n",
    "        \n",
    "    def setMetodoCod(self, value):\n",
    "        return self.set(self.metodoCod, value)\n",
    "\n",
    "    def getMetodoCod(self):\n",
    "        return self.getOrDefault(self.metodoCod)\n",
    "    \n",
    "class HasModeloCod(Params):\n",
    "    def __init__(self):\n",
    "        super(HasModeloCod, self).__init__()\n",
    "        self.modeloCod = Param(self, \"modeloCod\", \"modeloCod\", \n",
    "                                        typeConverter=TypeConverters.identity)\n",
    "        \n",
    "    def setModeloCod(self, value):\n",
    "        return self.set(self.modeloCod, value)\n",
    "\n",
    "    def getModeloCod(self):\n",
    "        return self.getOrDefault(self.modeloCod)\n",
    "    \n",
    "# Clase que define el estimador\n",
    "class CodificacionCategoricasEstimator(Estimator, HasMetodoCod,\n",
    "                                  DefaultParamsReadable, DefaultParamsWritable):\n",
    "    @keyword_only\n",
    "    def __init__(self, metodoCod = \"OneHotEncoder\"):\n",
    "        super(CodificacionCategoricasEstimator, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "    \n",
    "    @keyword_only\n",
    "    def setParams(self, metodoCod = \"OneHotEncoder\"):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "    \n",
    "    def _fit(self, df):\n",
    "        columnas_categoricas=[]\n",
    "        if \"target\" in df.columns:\n",
    "            columnas_sin_target = df.drop(\"target\").columns\n",
    "        else:\n",
    "            columnas_sin_target = df.columns\n",
    "        for c in columnas_sin_target:\n",
    "            if df.select(c).dtypes[0][1] in [\"string\"]:\n",
    "                columnas_categoricas.append(c)\n",
    "        metodo = self.getMetodoCod()\n",
    "        if metodo == \"OneHotEncoder\":\n",
    "            # Necesitamos aplicar previamente a OneHotEncoder una codificación adicional, StringIndexer.\n",
    "            # Esto es necesario por la forma en que OneHotEncoder está implementado en MLlib.\n",
    "            # Meteremos ambos estimadores en una pipeline.\n",
    "            indexers = [StringIndexer(inputCol=columna, outputCol=columna+\"-\") for columna in columnas_categoricas]\n",
    "            encoder = OneHotEncoder(\n",
    "              inputCols=[indexer.getOutputCol() for indexer in indexers],\n",
    "                outputCols=[\"{0}encoded\".format(indexer.getOutputCol()) for indexer in indexers]\n",
    "            )\n",
    "            pipeline = Pipeline(stages=indexers + [encoder])\n",
    "            encoder = pipeline.fit(df)\n",
    "        if metodo == \"StringIndexer\":\n",
    "            encoder = StringIndexer(inputCols=[columna for columna in columnas_categoricas], \n",
    "                                    outputCol=[columna+\"-encoded\" for columna in columnas_categoricas]) \n",
    "\n",
    "            encoder = encoder.fit(df)\n",
    "        return CodificacionCategoricasModel(modeloCod=encoder, columnasCod=columnas_categoricas)\n",
    "\n",
    "# Clase que define el transformer\n",
    "class CodificacionCategoricasModel(Model, HasModeloCod, HasColumnasCod, \n",
    "                                   DefaultParamsReadable, DefaultParamsWritable):\n",
    "    @keyword_only\n",
    "    def __init__(self, modeloCod = \"\", columnasCod=[]):\n",
    "        super(CodificacionCategoricasModel, self).__init__()\n",
    "        kwargs = self._input_kwargs\n",
    "        self.setParams(**kwargs)\n",
    "\n",
    "    @keyword_only\n",
    "    def setParams(self, modeloCod = \"\", columnasCod=[]):\n",
    "        kwargs = self._input_kwargs\n",
    "        return self._set(**kwargs)\n",
    "    \n",
    "    def _transform(self, df):\n",
    "        modelo = self.getModeloCod()\n",
    "        columnas_Cod = self.getColumnasCod()\n",
    "        df = modelo.transform(df)\n",
    "        df = df.drop(*columnas_Cod)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d81e60",
   "metadata": {},
   "source": [
    "Una vez que hemos definido todos los metodos de preprocesamiento que vamos a aplicar a nuestro conjunto de datos, estamos listos para aplicarlos y obtener nuestro nuevo conjunto de datos trasnformado. Lo que haremos será definir las clases de los estimadores de los métodos seleccionando las opciones deseadas en cada caso y los meteremos todos en una pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1d2cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "deteccion_constantes = DeteccionConstantesEstimator()\n",
    "missings = ImputacionMissingsEstimator(porcentajeMissings=0.5, metodoImputacionNumericas=\"Mediana\")\n",
    "outliers = OutliersEstimator(metodoOutliers=\"Mediana\")\n",
    "codificacion_categoricas = CodificacionCategoricasEstimator(metodoCod=\"OneHotEncoder\")\n",
    "pipeline = Pipeline(stages=[deteccion_constantes, missings, outliers, codificacion_categoricas])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2f83f8",
   "metadata": {},
   "source": [
    "De momento no aplicaremos el preprocesado a nuestro conjunto de datos pues en este Jupyter no vamos a realizar nada más. Lo guardaremos para utilizarlo en el Jupyter en el que ajustaremos los modelos de Machine Learning. Para guardar la pipeline utilizaremos el método save que nos permite guardarla con el formato de Spark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "354eaa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipeline.write().overwrite().save(\"pipeline_preprocesado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
